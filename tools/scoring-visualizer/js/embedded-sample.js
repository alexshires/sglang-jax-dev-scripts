export const EMBEDDED_SAMPLE_DATASET = {
  dataset_version: "1.0.0",
  generated_on: "2026-02-14",
  source: {
    kind: "embedded-fallback",
    note: "Fallback dataset used when external sample JSON is unavailable.",
  },
  example: {
    request_id: "rerank-support-docs-0007",
    query_text:
      "Rank these candidate snippets for the question: 'How does JAX TPU score API isolate attention across packed items while keeping high throughput?'",
    items: [
      {
        id: "item_1",
        text: "Packed mode uses one extend pass with block-diagonal custom_mask so each item only attends to itself plus query tokens.",
      },
      {
        id: "item_2",
        text: "Prefill+extend computes query KV cache once and reuses it across item extends; this reduces repeated prefix attention cost.",
      },
      {
        id: "item_3",
        text: "Chunk size controls packed throughput and memory pressure; larger chunks can increase items/sec until memory limits.",
      },
      {
        id: "item_4",
        text: "If delimiters are misaligned, extracted scores can drift because boundary logprobs are read from wrong positions.",
      },
      {
        id: "item_5",
        text: "Disable radix cache for packed multi-item correctness in current rollout constraints.",
      },
      {
        id: "item_6",
        text: "Score extraction gathers token logprobs at delimiter boundaries and maps them to label_token_ids.",
      },
      {
        id: "item_7",
        text: "Very long static prefixes reduce packed efficiency because shared context still dominates the compute graph.",
      },
      {
        id: "item_8",
        text: "Prefill+extend mode shifts cost toward one cache creation stage and many cheap extend stages.",
      },
    ],
    label_token_ids: [24561, 12032],
    label_names: ["relevant", "not_relevant"],
  },
  modes: {
    packed: {
      title: "Packed multi-item",
      cache: { supported: false, status: "not_applicable", hits: 0, misses: 0 },
      summary_metrics: {
        total_latency_ms: 171.2,
        items_per_sec: 46.7,
        compiler_cache: "warm",
      },
      stages: [
        {
          id: "input_tokenization",
          name: "Input / tokenization",
          latency_ms: 6.4,
          status: "active",
          description: "Tokenize query, items, and labels.",
          reused: "Tokenizer process and vocabulary tables.",
          recomputed: "Token IDs for all 8 items.",
          throughput_impact: "Small fixed overhead at request start.",
        },
        {
          id: "prefix_query_handling",
          name: "Prefix / query handling",
          latency_ms: 18.1,
          status: "active",
          description: "Construct packed layout and offsets.",
          reused: "Delimiter rules and prefix templates.",
          recomputed: "Packed offsets for this request.",
          throughput_impact: "Moderate setup cost before forward pass.",
        },
        {
          id: "cache_creation",
          name: "Cache creation",
          latency_ms: 0,
          status: "skipped",
          description: "No reusable KV cache stage in packed flow.",
          reused: "None.",
          recomputed: "Prefix attention is part of packed forward.",
          throughput_impact: "No upfront cache, no cache reuse.",
        },
        {
          id: "extend_batch_processing",
          name: "Extend batch processing",
          latency_ms: 122.8,
          status: "active",
          description: "Main packed extend forward pass.",
          reused: "Compiled kernels and model weights.",
          recomputed: "Packed attention graph for request tokens.",
          throughput_impact: "Dominant latency stage.",
        },
        {
          id: "attention_isolation",
          name: "Attention isolation concept",
          latency_ms: 16.7,
          status: "active",
          description: "Apply block-diagonal mask for isolation.",
          reused: "Kernel path and shape-specialized variants.",
          recomputed: "Mask values and boundaries per request.",
          throughput_impact: "Correctness overhead for strict isolation.",
        },
        {
          id: "score_extraction",
          name: "Score extraction",
          latency_ms: 7.2,
          status: "active",
          description: "Gather boundary logprobs and map labels.",
          reused: "Extraction operators.",
          recomputed: "Per-item boundary gathers.",
          throughput_impact: "Low final-stage overhead.",
        },
      ],
      scores: [
        { item_id: "item_1", relevant: 0.91, not_relevant: 0.09 },
        { item_id: "item_2", relevant: 0.95, not_relevant: 0.05 },
        { item_id: "item_3", relevant: 0.86, not_relevant: 0.14 },
        { item_id: "item_4", relevant: 0.68, not_relevant: 0.32 },
        { item_id: "item_5", relevant: 0.61, not_relevant: 0.39 },
        { item_id: "item_6", relevant: 0.89, not_relevant: 0.11 },
        { item_id: "item_7", relevant: 0.83, not_relevant: 0.17 },
        { item_id: "item_8", relevant: 0.93, not_relevant: 0.07 },
      ],
    },
    prefill_extend: {
      title: "Prefill+extend multi-item",
      cache: { supported: true, status: "miss_then_hit", hits: 7, misses: 1 },
      summary_metrics: {
        total_latency_ms: 30.8,
        items_per_sec: 259.7,
        compiler_cache: "warm",
      },
      stages: [
        {
          id: "input_tokenization",
          name: "Input / tokenization",
          latency_ms: 5.8,
          status: "active",
          description: "Tokenize query/items once before split execution.",
          reused: "Tokenizer process and vocabulary tables.",
          recomputed: "Token IDs for this request.",
          throughput_impact: "Small fixed overhead.",
        },
        {
          id: "prefix_query_handling",
          name: "Prefix / query handling",
          latency_ms: 3.1,
          status: "active",
          description: "Prepare one query-prefix payload.",
          reused: "Prefix metadata for downstream extends.",
          recomputed: "Per-request query metadata.",
          throughput_impact: "Lower setup cost than packed layout.",
        },
        {
          id: "cache_creation",
          name: "Cache creation",
          latency_ms: 8.9,
          status: "active",
          description: "Prefill query once to build KV cache.",
          reused: "Query KV cache shared across item extends.",
          recomputed: "Initial miss populates cache.",
          throughput_impact: "Front-loads work to make extends cheap.",
        },
        {
          id: "extend_batch_processing",
          name: "Extend batch processing",
          latency_ms: 9.2,
          status: "active",
          description: "Run short per-item extends against shared prefix KV.",
          reused: "Prefix KV pages and compiled kernels.",
          recomputed: "Item-tail attention only.",
          throughput_impact: "Primary throughput win for long-query workloads.",
        },
        {
          id: "attention_isolation",
          name: "Attention isolation concept",
          latency_ms: 1.7,
          status: "active",
          description: "Per-item extend contexts remain isolated over shared prefix.",
          reused: "Shared prefix pages are read-only.",
          recomputed: "Independent item windows.",
          throughput_impact: "Lower overhead than packed mask path.",
        },
        {
          id: "score_extraction",
          name: "Score extraction",
          latency_ms: 2.1,
          status: "active",
          description: "Collect per-item label scores.",
          reused: "Projection and extraction operators.",
          recomputed: "Per-item boundary gathers.",
          throughput_impact: "Small final stage.",
        },
      ],
      scores: [
        { item_id: "item_1", relevant: 0.91, not_relevant: 0.09 },
        { item_id: "item_2", relevant: 0.96, not_relevant: 0.04 },
        { item_id: "item_3", relevant: 0.87, not_relevant: 0.13 },
        { item_id: "item_4", relevant: 0.69, not_relevant: 0.31 },
        { item_id: "item_5", relevant: 0.6, not_relevant: 0.4 },
        { item_id: "item_6", relevant: 0.9, not_relevant: 0.1 },
        { item_id: "item_7", relevant: 0.84, not_relevant: 0.16 },
        { item_id: "item_8", relevant: 0.94, not_relevant: 0.06 },
      ],
    },
  },
};
