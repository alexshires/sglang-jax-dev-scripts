/home/kanna/work/sglang-jax/.venv/lib/python3.12/site-packages/jax/_src/cloud_tpu_init.py:93: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c "echo always > /sys/kernel/mm/transparent_hugepage/enabled")
  warnings.warn(
INFO:sgl_jax.srt.entrypoints.engine:server_args=ServerArgs(model_path='/models/Qwen/Qwen3-0.6B', tokenizer_path='/models/Qwen/Qwen3-0.6B', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, revision=None, model_impl='auto', model_layer_nums=None, host='127.0.0.1', port=30000, skip_server_warmup=True, warmups=None, dtype='bfloat16', quantization=None, quantization_param_path=None, quantization_config_path=None, kv_cache_dtype='auto', mem_fraction_static=0.7, max_running_requests=12, max_total_tokens=None, max_prefill_tokens=32768, chunked_prefill_size=-1, enable_mixed_chunk=False, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=64, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='tpu', device_indexes=None, tp_size=1, ep_size=1, stream_interval=1, stream_output=False, random_seed=42, constrained_json_whitespace_pattern=None, constrained_json_disable_any_whitespace=False, watchdog_timeout=300, dist_timeout=None, download_dir=None, sleep_on_idle=False, dp_size=1, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, crash_dump_folder=None, show_time_cost=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, api_key=None, served_model_name='/models/Qwen/Qwen3-0.6B', file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, disable_radix_cache=False, allow_auto_truncate=False, enable_tokenizer_batch_encode=False, disable_overlap_schedule=False, enable_precision_tracer=False, attention_backend='fa', moe_backend='epmoe', grammar_backend='llguidance', max_seq_len=4096, precompile_token_paddings=[1024, 4096, 16384], precompile_bs_paddings=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], disable_precompile=False, speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_num_steps=4, speculative_eagle_topk=5, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, enable_deterministic_sampling=False, enable_single_process=False, enable_nan_detection=False, use_sort_for_toppk_minp=False, multi_item_scoring_delimiter=151643, max_multi_item_seq_len=32768, max_multi_item_count=512, multi_item_scoring_chunk_size=500, multi_item_mask_impl='dense', multi_item_segment_fallback_threshold=0, multi_item_enable_prefill_extend=True, multi_item_extend_batch_size=12, multi_item_prefill_extend_cache_timeout=60.0, enable_scoring_cache=True, enable_lora=False, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_eviction_policy='lru', enable_static_lora=False, lora_scaling=None, enable_engine_loop_run_forever_daemon=False, multimodal=False, enable_return_routed_experts=False)
[2026-02-14 15:52:57] server_args=ServerArgs(model_path='/models/Qwen/Qwen3-0.6B', tokenizer_path='/models/Qwen/Qwen3-0.6B', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, revision=None, model_impl='auto', model_layer_nums=None, host='127.0.0.1', port=30000, skip_server_warmup=True, warmups=None, dtype='bfloat16', quantization=None, quantization_param_path=None, quantization_config_path=None, kv_cache_dtype='auto', mem_fraction_static=0.7, max_running_requests=12, max_total_tokens=None, max_prefill_tokens=32768, chunked_prefill_size=-1, enable_mixed_chunk=False, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=64, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='tpu', device_indexes=None, tp_size=1, ep_size=1, stream_interval=1, stream_output=False, random_seed=42, constrained_json_whitespace_pattern=None, constrained_json_disable_any_whitespace=False, watchdog_timeout=300, dist_timeout=None, download_dir=None, sleep_on_idle=False, dp_size=1, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, crash_dump_folder=None, show_time_cost=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, api_key=None, served_model_name='/models/Qwen/Qwen3-0.6B', file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, disable_radix_cache=False, allow_auto_truncate=False, enable_tokenizer_batch_encode=False, disable_overlap_schedule=False, enable_precision_tracer=False, attention_backend='fa', moe_backend='epmoe', grammar_backend='llguidance', max_seq_len=4096, precompile_token_paddings=[1024, 4096, 16384], precompile_bs_paddings=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], disable_precompile=False, speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_num_steps=4, speculative_eagle_topk=5, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, enable_deterministic_sampling=False, enable_single_process=False, enable_nan_detection=False, use_sort_for_toppk_minp=False, multi_item_scoring_delimiter=151643, max_multi_item_seq_len=32768, max_multi_item_count=512, multi_item_scoring_chunk_size=500, multi_item_mask_impl='dense', multi_item_segment_fallback_threshold=0, multi_item_enable_prefill_extend=True, multi_item_extend_batch_size=12, multi_item_prefill_extend_cache_timeout=60.0, enable_scoring_cache=True, enable_lora=False, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_eviction_policy='lru', enable_static_lora=False, lora_scaling=None, enable_engine_loop_run_forever_daemon=False, multimodal=False, enable_return_routed_experts=False)
INFO:sgl_jax.srt.configs.model_config:No quantization config found in HF config or user config
[2026-02-14 15:52:57] No quantization config found in HF config or user config
/home/kanna/work/sglang-jax/.venv/lib/python3.12/site-packages/jax/_src/cloud_tpu_init.py:93: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c "echo always > /sys/kernel/mm/transparent_hugepage/enabled")
  warnings.warn(
/home/kanna/work/sglang-jax/.venv/lib/python3.12/site-packages/jax/_src/cloud_tpu_init.py:93: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c "echo always > /sys/kernel/mm/transparent_hugepage/enabled")
  warnings.warn(
INFO:sgl_jax.srt.configs.model_config:No quantization config found in HF config or user config
[2026-02-14 15:52:59] No quantization config found in HF config or user config
INFO:sgl_jax.srt.constrained.llguidance_backend:Initialized GuidanceBackend with whitespace_pattern=None
[2026-02-14 15:53:00] Initialized GuidanceBackend with whitespace_pattern=None
INFO:sgl_jax.srt.configs.model_config:No quantization config found in HF config or user config
[2026-02-14 15:53:05] No quantization config found in HF config or user config
INFO:sgl_jax.srt.precision_tracer:Precision tracer globally disabled
[2026-02-14 15:53:05] Precision tracer globally disabled
INFO:sgl_jax.srt.configs.model_config:KV heads distribution for GQA model: original_kv_heads=8, tp_size=1, each device gets 8 head(s), no replication needed, padding_strategy=replicate
[2026-02-14 15:53:06] KV heads distribution for GQA model: original_kv_heads=8, tp_size=1, each device gets 8 head(s), no replication needed, padding_strategy=replicate
INFO:sgl_jax.srt.models.qwen3:QWen3ForCausalLMModel config dtype: <class 'jax.numpy.bfloat16'>
[2026-02-14 15:53:06] QWen3ForCausalLMModel config dtype: <class 'jax.numpy.bfloat16'>
INFO:sgl_jax.srt.model_loader.loader:No quantization config found. Skipping quantization.
[2026-02-14 15:53:06] No quantization config found. Skipping quantization.
INFO:sgl_jax.srt.utils.weight_utils:Scanning metadata for 1 model files (single host only)...
[2026-02-14 15:53:06] Scanning metadata for 1 model files (single host only)...
Scanning Metadata:   0%|          | 0/1 [00:00<?, ?file/s]Scanning Metadata: 100%|██████████| 1/1 [00:00<00:00, 169.65file/s]
INFO:sgl_jax.srt.utils.weight_utils:Starting parallel weight loading via JAX Lazy Loader...
[2026-02-14 15:53:06] Starting parallel weight loading via JAX Lazy Loader...
Loading Regular Weights:   0%|          | 0/310 [00:00<?, ?it/s]Loading Regular Weights:   0%|          | 1/310 [00:00<00:49,  6.24it/s]Loading Regular Weights:   2%|▏         | 6/310 [00:00<00:13, 22.72it/s]Loading Regular Weights:   4%|▎         | 11/310 [00:00<00:10, 28.57it/s]Loading Regular Weights:  11%|█▏        | 35/310 [00:00<00:02, 94.25it/s]Loading Regular Weights:  31%|███       | 96/310 [00:00<00:00, 251.83it/s]Loading Regular Weights:  50%|█████     | 156/310 [00:00<00:00, 354.49it/s]Loading Regular Weights:  70%|███████   | 217/310 [00:00<00:00, 430.30it/s]Loading Regular Weights:  89%|████████▉ | 276/310 [00:00<00:00, 477.57it/s]Loading Regular Weights: 100%|██████████| 310/310 [00:01<00:00, 308.68it/s]
Loading MoE Weights: 0it [00:00, ?it/s]Loading MoE Weights: 0it [00:00, ?it/s]
INFO:sgl_jax.srt.utils.weight_utils:All weights loaded successfully.
[2026-02-14 15:53:07] All weights loaded successfully.
INFO:sgl_jax.srt.models.qwen3:Qwen3 weights loaded successfully!
[2026-02-14 15:53:07] Qwen3 weights loaded successfully!
INFO:sgl_jax.srt.model_executor.model_runner:ModelRunner kv_cache_dtype: <class 'jax.numpy.bfloat16'>
[2026-02-14 15:53:07] ModelRunner kv_cache_dtype: <class 'jax.numpy.bfloat16'>
INFO:sgl_jax.srt.model_executor.model_runner:TPU Memory profiling: available_device_memory=30.1GB, available_kv_cache=20.8GB, max_tokens=194379, cell_size=114688bytes
[2026-02-14 15:53:07] TPU Memory profiling: available_device_memory=30.1GB, available_kv_cache=20.8GB, max_tokens=194379, cell_size=114688bytes
INFO:sgl_jax.srt.model_executor.model_runner:ModelRunner max_total_num_tokens: 194368
[2026-02-14 15:53:07] ModelRunner max_total_num_tokens: 194368
INFO:sgl_jax.srt.mem_cache.memory_pool:Creating fused KV buffers for 28 layers
[2026-02-14 15:53:07] Creating fused KV buffers for 28 layers
INFO:sgl_jax.srt.mem_cache.memory_pool:Total fused KV cache memory per layer: 0.74 GB, dtype: <class 'jax.numpy.bfloat16'>
[2026-02-14 15:53:07] Total fused KV cache memory per layer: 0.74 GB, dtype: <class 'jax.numpy.bfloat16'>
INFO:sgl_jax.srt.mem_cache.memory_pool:Total time to create 28 buffers: 0.76 seconds
[2026-02-14 15:53:08] Total time to create 28 buffers: 0.76 seconds
INFO:sgl_jax.srt.mem_cache.memory_pool:JAX Fused KV Cache allocated. #tokens: 194368, Fused KV size: 20.77 GB
[2026-02-14 15:53:08] JAX Fused KV Cache allocated. #tokens: 194368, Fused KV size: 20.77 GB
INFO:sgl_jax.srt.managers.tp_worker:Max running requests constraints:
[2026-02-14 15:53:08] Max running requests constraints:
INFO:sgl_jax.srt.managers.tp_worker:  - Server limit: 12 (configured)
[2026-02-14 15:53:08]   - Server limit: 12 (configured)
INFO:sgl_jax.srt.managers.tp_worker:  - Token pool size: 13
[2026-02-14 15:53:08]   - Token pool size: 13
INFO:sgl_jax.srt.managers.tp_worker:  - Attention backend: 204 (context_len=40960, page_size=64)
[2026-02-14 15:53:08]   - Attention backend: 204 (context_len=40960, page_size=64)
INFO:sgl_jax.srt.managers.tp_worker:  → Final max_running_requests: 12
[2026-02-14 15:53:08]   → Final max_running_requests: 12
INFO:sgl_jax.srt.managers.scheduler:[Scheduler] Begins to run worker precompile.
[2026-02-14 15:53:08] [Scheduler] Begins to run worker precompile.
INFO:sgl_jax.srt.managers.tp_worker:[EXTEND] Begin to precompile bs_paddings=[12] token_paddings=[1024, 4096, 16384, 32768]
[2026-02-14 15:53:08] [EXTEND] Begin to precompile bs_paddings=[12] token_paddings=[1024, 4096, 16384, 32768]
[EXTEND] PRECOMPILE:   0%|          | 0/4 [00:00<?, ?it/s][EXTEND] PRECOMPILE:   0%|          | 0/4 [00:00<?, ?it/s, bs=12, tokens=1024]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=1024, pages_per_seq=640.
[2026-02-14 15:53:08] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=1024, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:53:08] Using default block size: bkv_p=16, bq=32.
[EXTEND] PRECOMPILE:  25%|██▌       | 1/4 [00:11<00:34, 11.50s/it, bs=12, tokens=1024][EXTEND] PRECOMPILE:  25%|██▌       | 1/4 [00:11<00:34, 11.50s/it, bs=12, tokens=4096]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=4096, pages_per_seq=640.
[2026-02-14 15:53:20] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=4096, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:53:20] Using default block size: bkv_p=16, bq=32.
[EXTEND] PRECOMPILE:  50%|█████     | 2/4 [00:22<00:22, 11.23s/it, bs=12, tokens=4096][EXTEND] PRECOMPILE:  50%|█████     | 2/4 [00:22<00:22, 11.23s/it, bs=12, tokens=16384]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=16384, pages_per_seq=640.
[2026-02-14 15:53:31] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=16384, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:53:31] Using default block size: bkv_p=16, bq=32.
[EXTEND] PRECOMPILE:  75%|███████▌  | 3/4 [00:32<00:10, 10.73s/it, bs=12, tokens=16384][EXTEND] PRECOMPILE:  75%|███████▌  | 3/4 [00:32<00:10, 10.73s/it, bs=12, tokens=32768]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=32768, pages_per_seq=640.
[2026-02-14 15:53:41] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=32768, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:53:41] Using default block size: bkv_p=16, bq=32.
[EXTEND] PRECOMPILE: 100%|██████████| 4/4 [00:42<00:00, 10.23s/it, bs=12, tokens=32768]                                                                                       INFO:sgl_jax.srt.managers.tp_worker:[EXTEND] Precompile finished in 42 secs
[2026-02-14 15:53:50] [EXTEND] Precompile finished in 42 secs
INFO:sgl_jax.srt.managers.tp_worker:[DECODE] Begin to precompile bs_paddings=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
[2026-02-14 15:53:50] [DECODE] Begin to precompile bs_paddings=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
[DECODE] PRECOMPILE:   0%|          | 0/12 [00:00<?, ?it/s][DECODE] PRECOMPILE:   0%|          | 0/12 [00:00<?, ?it/s, bs=1]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=1, pages_per_seq=640.
[2026-02-14 15:53:50] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=1, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:53:50] Using default block size: bkv_p=16, bq=32.
[DECODE] PRECOMPILE:   8%|▊         | 1/12 [00:06<01:11,  6.51s/it, bs=1][DECODE] PRECOMPILE:   8%|▊         | 1/12 [00:06<01:11,  6.51s/it, bs=2]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=2, pages_per_seq=640.
[2026-02-14 15:53:57] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=2, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:53:57] Using default block size: bkv_p=16, bq=32.
[DECODE] PRECOMPILE:  17%|█▋        | 2/12 [00:12<01:04,  6.45s/it, bs=2][DECODE] PRECOMPILE:  17%|█▋        | 2/12 [00:12<01:04,  6.45s/it, bs=3]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=3, pages_per_seq=640.
[2026-02-14 15:54:03] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=3, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:54:03] Using default block size: bkv_p=16, bq=32.
[DECODE] PRECOMPILE:  25%|██▌       | 3/12 [00:19<00:57,  6.42s/it, bs=3][DECODE] PRECOMPILE:  25%|██▌       | 3/12 [00:19<00:57,  6.42s/it, bs=4]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=4, pages_per_seq=640.
[2026-02-14 15:54:10] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=4, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:54:10] Using default block size: bkv_p=16, bq=32.
[DECODE] PRECOMPILE:  33%|███▎      | 4/12 [00:25<00:50,  6.33s/it, bs=4][DECODE] PRECOMPILE:  33%|███▎      | 4/12 [00:25<00:50,  6.33s/it, bs=5]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=5, pages_per_seq=640.
[2026-02-14 15:54:16] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=5, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:54:16] Using default block size: bkv_p=16, bq=32.
[DECODE] PRECOMPILE:  42%|████▏     | 5/12 [00:31<00:44,  6.37s/it, bs=5][DECODE] PRECOMPILE:  42%|████▏     | 5/12 [00:31<00:44,  6.37s/it, bs=6]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=6, pages_per_seq=640.
[2026-02-14 15:54:22] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=6, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:54:22] Using default block size: bkv_p=16, bq=32.
[DECODE] PRECOMPILE:  50%|█████     | 6/12 [00:38<00:38,  6.43s/it, bs=6][DECODE] PRECOMPILE:  50%|█████     | 6/12 [00:38<00:38,  6.43s/it, bs=7]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=7, pages_per_seq=640.
[2026-02-14 15:54:29] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=7, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:54:29] Using default block size: bkv_p=16, bq=32.
[DECODE] PRECOMPILE:  58%|█████▊    | 7/12 [00:45<00:32,  6.47s/it, bs=7][DECODE] PRECOMPILE:  58%|█████▊    | 7/12 [00:45<00:32,  6.47s/it, bs=8]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=8, pages_per_seq=640.
[2026-02-14 15:54:35] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=8, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:54:35] Using default block size: bkv_p=16, bq=32.
[DECODE] PRECOMPILE:  67%|██████▋   | 8/12 [00:52<00:26,  6.64s/it, bs=8][DECODE] PRECOMPILE:  67%|██████▋   | 8/12 [00:52<00:26,  6.64s/it, bs=9]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=9, pages_per_seq=640.
[2026-02-14 15:54:42] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=9, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:54:42] Using default block size: bkv_p=16, bq=32.
[DECODE] PRECOMPILE:  75%|███████▌  | 9/12 [00:59<00:20,  6.87s/it, bs=9][DECODE] PRECOMPILE:  75%|███████▌  | 9/12 [00:59<00:20,  6.87s/it, bs=10]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=10, pages_per_seq=640.
[2026-02-14 15:54:50] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=10, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:54:50] Using default block size: bkv_p=16, bq=32.
[DECODE] PRECOMPILE:  83%|████████▎ | 10/12 [01:07<00:14,  7.25s/it, bs=10][DECODE] PRECOMPILE:  83%|████████▎ | 10/12 [01:07<00:14,  7.25s/it, bs=11]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=11, pages_per_seq=640.
[2026-02-14 15:54:58] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=11, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:54:58] Using default block size: bkv_p=16, bq=32.
[DECODE] PRECOMPILE:  92%|█████████▏| 11/12 [01:15<00:07,  7.59s/it, bs=11][DECODE] PRECOMPILE:  92%|█████████▏| 11/12 [01:15<00:07,  7.59s/it, bs=12]INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=12, pages_per_seq=640.
[2026-02-14 15:55:06] Tuned RPA block sizes not found for TPU v6e: page_size=64, actual_num_q_heads=16, actual_num_kv_heads=8, head_dim=128, max_num_tokens=12, pages_per_seq=640.
INFO:sgl_jax.srt.kernels.ragged_paged_attention.tuned_block_sizes:Using default block size: bkv_p=16, bq=32.
[2026-02-14 15:55:06] Using default block size: bkv_p=16, bq=32.
[DECODE] PRECOMPILE: 100%|██████████| 12/12 [01:20<00:00,  6.70s/it, bs=12]                                                                           INFO:sgl_jax.srt.managers.tp_worker:[DECODE] Precompile finished in 81 secs
[2026-02-14 15:55:11] [DECODE] Precompile finished in 81 secs
INFO:sgl_jax.srt.managers.scheduler:[Scheduler] Completes worker precompile.
[2026-02-14 15:55:11] [Scheduler] Completes worker precompile.
[2026-02-14 15:55:11] INFO:     Started server process [1065200]
[2026-02-14 15:55:11] INFO:     Waiting for application startup.
INFO:sgl_jax.srt.entrypoints.http_server:The server is fired up and ready to roll!
[2026-02-14 15:55:11] INFO:     Application startup complete.
[2026-02-14 15:55:11] The server is fired up and ready to roll!
[2026-02-14 15:55:11] INFO:     Uvicorn running on http://127.0.0.1:30000 (Press CTRL+C to quit)
[2026-02-14 15:55:11] INFO:     127.0.0.1:59446 - "GET /health HTTP/1.1" 200 OK
INFO:sgl_jax.srt.managers.scheduler_metrics_mixin:Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 1, 
[2026-02-14 15:55:11] Prefill batch. #new-seq: 1, #new-token: 2048, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 1, 
INFO:sgl_jax.srt.managers.scheduler_output_processor_mixin:Prefill batch. #bid: 2, #cache_miss: 1
[2026-02-14 15:55:15] Prefill batch. #bid: 2, #cache_miss: 1
INFO:sgl_jax.srt.managers.scheduler_metrics_mixin:Prefill batch. #new-seq: 2, #new-token: 128, #cached-token: 3968, token usage: 0.01, #running-req: 0, #queue-req: 2, 
[2026-02-14 15:55:15] Prefill batch. #new-seq: 2, #new-token: 128, #cached-token: 3968, token usage: 0.01, #running-req: 0, #queue-req: 2, 
INFO:sgl_jax.srt.managers.scheduler_metrics_mixin:Prefill batch. #new-seq: 10, #new-token: 640, #cached-token: 19840, token usage: 0.01, #running-req: 0, #queue-req: 10, 
[2026-02-14 15:55:15] Prefill batch. #new-seq: 10, #new-token: 640, #cached-token: 19840, token usage: 0.01, #running-req: 0, #queue-req: 10, 
INFO:sgl_jax.srt.managers.scheduler_output_processor_mixin:Prefill batch. #bid: 4, #cache_miss: 2
[2026-02-14 15:55:35] Prefill batch. #bid: 4, #cache_miss: 2
INFO:sgl_jax.srt.managers.scheduler_output_processor_mixin:Prefill batch. #bid: 6, #cache_miss: 2
[2026-02-14 15:55:39] Prefill batch. #bid: 6, #cache_miss: 2
[2026-02-14 15:55:39] INFO:     127.0.0.1:59460 - "POST /v1/score HTTP/1.1" 200 OK
INFO:sgl_jax.srt.managers.scheduler_metrics_mixin:Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 1984, token usage: 0.01, #running-req: 0, #queue-req: 1, 
[2026-02-14 15:55:39] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 1984, token usage: 0.01, #running-req: 0, #queue-req: 1, 
INFO:sgl_jax.srt.managers.scheduler_metrics_mixin:Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 15872, token usage: 0.01, #running-req: 0, #queue-req: 8, 
[2026-02-14 15:55:39] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 15872, token usage: 0.01, #running-req: 0, #queue-req: 8, 
INFO:sgl_jax.srt.managers.scheduler_metrics_mixin:Prefill batch. #new-seq: 4, #new-token: 256, #cached-token: 7936, token usage: 0.01, #running-req: 0, #queue-req: 4, 
[2026-02-14 15:55:39] Prefill batch. #new-seq: 4, #new-token: 256, #cached-token: 7936, token usage: 0.01, #running-req: 0, #queue-req: 4, 
INFO:sgl_jax.srt.managers.scheduler_output_processor_mixin:Prefill batch. #bid: 10, #cache_miss: 2
[2026-02-14 15:55:59] Prefill batch. #bid: 10, #cache_miss: 2
INFO:sgl_jax.srt.managers.scheduler_output_processor_mixin:Prefill batch. #bid: 12, #cache_miss: 2
[2026-02-14 15:56:03] Prefill batch. #bid: 12, #cache_miss: 2
[2026-02-14 15:56:03] INFO:     127.0.0.1:37718 - "POST /v1/score HTTP/1.1" 200 OK
INFO:sgl_jax.srt.managers.scheduler_metrics_mixin:Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 1984, token usage: 0.01, #running-req: 0, #queue-req: 1, 
[2026-02-14 15:56:03] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 1984, token usage: 0.01, #running-req: 0, #queue-req: 1, 
INFO:sgl_jax.srt.managers.scheduler_metrics_mixin:Prefill batch. #new-seq: 3, #new-token: 192, #cached-token: 5952, token usage: 0.01, #running-req: 0, #queue-req: 3, 
[2026-02-14 15:56:03] Prefill batch. #new-seq: 3, #new-token: 192, #cached-token: 5952, token usage: 0.01, #running-req: 0, #queue-req: 3, 
INFO:sgl_jax.srt.managers.scheduler_metrics_mixin:Prefill batch. #new-seq: 9, #new-token: 576, #cached-token: 17856, token usage: 0.01, #running-req: 0, #queue-req: 9, 
[2026-02-14 15:56:03] Prefill batch. #new-seq: 9, #new-token: 576, #cached-token: 17856, token usage: 0.01, #running-req: 0, #queue-req: 9, 
INFO:sgl_jax.srt.managers.scheduler_output_processor_mixin:Prefill batch. #bid: 16, #cache_miss: 2
[2026-02-14 15:56:24] Prefill batch. #bid: 16, #cache_miss: 2
INFO:sgl_jax.srt.managers.scheduler_output_processor_mixin:Prefill batch. #bid: 18, #cache_miss: 2
[2026-02-14 15:56:28] Prefill batch. #bid: 18, #cache_miss: 2
[2026-02-14 15:56:28] INFO:     127.0.0.1:44844 - "POST /v1/score HTTP/1.1" 200 OK
INFO:sgl_jax.srt.managers.scheduler_metrics_mixin:Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 1984, token usage: 0.01, #running-req: 0, #queue-req: 1, 
[2026-02-14 15:56:28] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 1984, token usage: 0.01, #running-req: 0, #queue-req: 1, 
INFO:sgl_jax.srt.managers.scheduler_metrics_mixin:Prefill batch. #new-seq: 3, #new-token: 192, #cached-token: 5952, token usage: 0.01, #running-req: 0, #queue-req: 3, 
[2026-02-14 15:56:28] Prefill batch. #new-seq: 3, #new-token: 192, #cached-token: 5952, token usage: 0.01, #running-req: 0, #queue-req: 3, 
INFO:sgl_jax.srt.managers.scheduler_metrics_mixin:Prefill batch. #new-seq: 9, #new-token: 576, #cached-token: 17856, token usage: 0.01, #running-req: 0, #queue-req: 9, 
[2026-02-14 15:56:28] Prefill batch. #new-seq: 9, #new-token: 576, #cached-token: 17856, token usage: 0.01, #running-req: 0, #queue-req: 9, 
[2026-02-14 15:56:28] INFO:     127.0.0.1:58576 - "POST /v1/score HTTP/1.1" 200 OK
INFO:sgl_jax.srt.managers.scheduler_metrics_mixin:Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 1984, token usage: 0.01, #running-req: 0, #queue-req: 1, 
[2026-02-14 15:56:28] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 1984, token usage: 0.01, #running-req: 0, #queue-req: 1, 
INFO:sgl_jax.srt.managers.scheduler_metrics_mixin:Prefill batch. #new-seq: 4, #new-token: 256, #cached-token: 7936, token usage: 0.01, #running-req: 0, #queue-req: 4, 
[2026-02-14 15:56:28] Prefill batch. #new-seq: 4, #new-token: 256, #cached-token: 7936, token usage: 0.01, #running-req: 0, #queue-req: 4, 
INFO:sgl_jax.srt.managers.scheduler_metrics_mixin:Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 15872, token usage: 0.01, #running-req: 0, #queue-req: 8, 
[2026-02-14 15:56:28] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 15872, token usage: 0.01, #running-req: 0, #queue-req: 8, 
[2026-02-14 15:56:28] INFO:     127.0.0.1:58586 - "POST /v1/score HTTP/1.1" 200 OK
WARNING:sgl_jax.srt.managers.tokenizer_manager:SIGTERM received. signum=None frame=None. Draining requests and shutting down...
[2026-02-14 15:58:14] SIGTERM received. signum=None frame=None. Draining requests and shutting down...
*** SIGTERM received at time=1771084694 on cpu 8 ***
PC: @     0x717c9fb3575a  (unknown)  zmq_errno
    @     0x717db4989e56        208  absl::lts_20250814::AbslFailureSignalHandler()
    @     0x717db7a45330  (unknown)  (unknown)
https://symbolize.stripped_domain/r/?trace=717db7a9eb2c,717db7a4532f,717db7a4527d,717db498a05b,717db7a4532f&map= 
*** SIGTERM received by PID 1065294 (TID 1065294) on cpu 8, si_code=-6, from PID 1065294; stack trace: ***
PC: @     0x717db7a9eb2c  (unknown)  pthread_kill
    @     0x717b815ae682       1888  FailureSignalHandler()
    @     0x717db7a45330       3152  (unknown)
    @     0x717db7a4527e         32  raise
    @     0x717db498a05c        208  absl::lts_20250814::AbslFailureSignalHandler()
    @     0x717db7a45330  (unknown)  (unknown)
https://symbolize.stripped_domain/r/?trace=717db7a9eb2c,717b815ae681,717db7a4532f,717db7a4527d,717db498a05b,717db7a4532f&map= 
E0214 15:58:14.117179 1065294 coredump_hook.cc:248] RAW: Remote crash gathering disabled for SIGTERM.
WARNING:sgl_jax.srt.entrypoints.engine:Child process unexpectedly failed with exitcode=15. pid=1065295
[2026-02-14 15:58:14] Child process unexpectedly failed with exitcode=15. pid=1065295
WARNING:sgl_jax.srt.entrypoints.engine:Child process pid=1065295 frame=<frame at 0x72a64f538250, file '/home/kanna/work/sglang-jax/.venv/lib/python3.12/site-packages/zmq/asyncio.py', line 151, code <lambda>>
[2026-02-14 15:58:14] Child process pid=1065295 frame=<frame at 0x72a64f538250, file '/home/kanna/work/sglang-jax/.venv/lib/python3.12/site-packages/zmq/asyncio.py', line 151, code <lambda>>
E0214 15:58:14.472360 1065294 process_state.cc:778] RAW: Raising signal 15 with default behavior
INFO:sgl_jax.srt.managers.tokenizer_manager:Gracefully exiting... remaining number of requests 0
[2026-02-14 15:58:16] Gracefully exiting... remaining number of requests 0
ERROR:sgl_jax.srt.managers.tokenizer_manager:Dumping requests before crash. crash_dump_folder=None
[2026-02-14 15:58:16] Dumping requests before crash. crash_dump_folder=None
